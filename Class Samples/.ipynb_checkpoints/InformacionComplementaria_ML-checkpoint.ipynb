{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MauricioRR-Tec/Machine-Learning/blob/master/Notebooks/Module_2/InformacionComplementaria_ML.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Información complementaria\n",
    "\n",
    "---\n",
    "\n",
    "## Contenido de la Sección\n",
    "\n",
    "\n",
    "1.   Errores - Bias y Varianza\n",
    "2.   Entrenamiento - Sobreajuste y Subajuste (General)\n",
    "3.   Errores en modelos de regresión\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.- Errores\n",
    "En **Machine Learning**, tenemos muy presente lo siguiente: \"Precisión\".\n",
    "\n",
    "Cuando nos enfrentamos al desarrollo de un modelo, nos debemos esforzar considerando lograr la mejor precisión y un adecuado ajuste de parámetros.\n",
    "\n",
    "En la práctica siempre habrá \"alti-bajos\" para dicha construcción, por lo que no siempre podremos construir un modelo con una precisión del 100% por diversas cuestiones (siempre sujetos a errores). \n",
    "\n",
    "![img](https://cdn.diferenciador.com/imagenes/exactitud-4-cke.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos comprender las diferentes fuentes de error de predicción, los cuales se dividen en estas parte:\n",
    "* `Error de Bias`\n",
    "* `Error de Varianza`\n",
    "* `Error de Irreducible`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error de Bias\n",
    "\n",
    "**Diferencia entre la predicción esperada de nuestro modelo y los valores verdaderos**.\n",
    "\n",
    "Aunque al final nuestro objetivo es siempre construir modelos que puedan predecir datos muy cercanos a los *valores verdaderos*, no siempre es tan fácil.\n",
    "\n",
    "Ejemplo: Ajustar una regresión lineal a un conjunto de datos que tiene un patrón no lineal (Ajuste insuficiente).\n",
    "\n",
    "En general, los algoritmos paramétricos como la regresión lineal, tienen un alto bias que los hace rápidos de aprender y más fácil de entender, pero generalmente menos flexibles. A su vez, tienen un menor rendimiento predictivo en problemas complejos.\n",
    "\n",
    "![img](https://i0.wp.com/live.staticflickr.com/65535/48057227231_5aacf1e5ac_c.jpg?resize=800%2C502&ssl=1)\n",
    "\n",
    "\n",
    "    Bajo bias: sugiere menos suposiciones sobre la forma de la función objetivo.\n",
    "    Alto bias: sugiere más suposiciones sobre la forma de la función objetivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error de varianza\n",
    "\n",
    "**Cantidad que la estimación de la función objetivo cambiará si se utiliza diferentes datos de entrenamiento**.\n",
    "\n",
    "La función objetivo se estima a partir de los datos de entrenamiento mediante un algoritmo de Machine Learning, por lo que deberíamos esperar que el algoritmo tenga alguna variación. \n",
    "\n",
    "Idealmente no debería cambiar demasiado de un conjunto de datos de entrenamiento a otro, lo que significa que el algoritmo es bueno para elegir el mapeo subyacente oculto entre las variables de entrada y de salida.\n",
    "\n",
    "---\n",
    "\n",
    "**Los algoritmos de Machine Learning que tienen una gran varianza están fuertemente influenciados por los detalles de los datos de entrenamiento, esto significa que los detalles de la capacitación influyen en el número y los tipos de parámetros utilizados para caracterizar la función de mapeo**.\n",
    "\n",
    "![img](https://i2.wp.com/live.staticflickr.com/65535/48057275418_bf2cae6f83_c.jpg?resize=800%2C577&ssl=1)\n",
    "\n",
    "    \n",
    "    Varianza baja: sugiere pequeños cambios en la estimación de la función objetivo con cambios en el conjunto de datos de capacitación.\n",
    "    Alta varianza: sugiere grandes cambios en la estimación de la función objetivo con cambios en el conjunto de datos de capacitación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importante !\n",
    "\n",
    "Los que de plano no se pueden \"reducir\" son los errores de tipo **Irreducibes**. \n",
    "\n",
    "También se le conoce como ruido y, por lo general, proviene por factores como variables desconocidas que influyen en el mapeo de las variables de entrada a la variable de salida, un conjunto de características incompleto o **un problema mal enmarcado**. Acá es importante comprender que no importa cuán bueno hagamos nuestro modelo, nuestros datos tendrán cierta cantidad de ruido o un error irreductible que no se puede eliminar.\n",
    "\n",
    "---\n",
    "\n",
    "Traduciendo el mapa de tiro con arco a estos conceptos...\n",
    "\n",
    "![img](https://i1.wp.com/live.staticflickr.com/65535/48057226411_5cdfc33307_c.jpg?resize=800%2C746&ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error total\n",
    "\n",
    "Comprender el bias y la varianza es fundamental para comprender el comportamiento de los modelos de predicción, pero en general lo que realmente importa es el **error general**, no la descomposición específica. \n",
    "\n",
    "El punto ideal para cualquier modelo es el nivel de complejidad en el que el aumento en el bias es equivalente a la reducción en la varianza.\n",
    "\n",
    "![img](https://i0.wp.com/live.staticflickr.com/7927/46138669365_b98531b89d_c.jpg?resize=800%2C505&ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2.- Entrenamiento\n",
    "\n",
    "Cuando trabajamos con un conjunto de datos para predecir o clasificar un problema, tendemos a encontrar la precisión implementando un modelo con el conjunto de datos de entrenamiento y luego con el conjunto de datos de pruebas.\n",
    "\n",
    "Si la precisión es satisfactoria, tendemos a aumentar la precisión de la predicción con el conjuntos de datos, ya sea aumentando o disminuyendo la selección de las característicos o modificando las condiciones de nuestro modelo de Machine Learning, pero con esto, en ocasiones el modelo puede dar resultados pobres.\n",
    "\n",
    "---\n",
    "Rendimiento pobre: se debe a que el modelo es demasiado **simple** para describir el objetivo, o, por el contrario, **complejo** para expresar el objetivo. \n",
    "\n",
    "Es en este momento que se debe tener claro los conceptos de sobreajuste y subajuste o “overfitting” y “underfitting”, como se le conoce en inglés.\n",
    "![img](https://i2.wp.com/live.staticflickr.com/65535/48057305423_0653b5e58f_c.jpg?resize=800%2C292&ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Machine Learning, predecimos y clasificamos nuestros datos de forma más general, entonces, para resolver el problema de nuestro modelo que esta sobreajustado o subajustado, debemos verlos por separado uno por uno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subajuste\n",
    "---\n",
    "El ajuste insuficiente destruye la precisión de nuestro modelo de Machine Learning. Su aparición simplemente significa que nuestro modelo o el algoritmo no se ajusta a los datos lo suficientemente bien. Suele suceder cuando tenemos menos datos para construir un modelo preciso y también cuando intentamos construir un modelo lineal con datos no lineales.\n",
    "\n",
    "En tales casos, las reglas del modelo de Machine Learning son demasiado fáciles y flexibles para aplicarse a datos tan mínimos y, por lo tanto, es probable que el modelo haga muchas predicciones erróneas. La falta de adaptación se puede evitar utilizando más datos y también reduciendo las características por selección de características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobreajuste\n",
    "---\n",
    "Esto ocurre cuando un modelo aprende el detalle, incluyendo el ruido en los datos de entrenamiento en la medida en que tiene un impacto negativo en el rendimiento del modelo en datos nuevos. Esto significa que el ruido o las fluctuaciones aleatorias en los datos de entrenamiento son recogidos y aprendidos por el modelo. El problema es que estos conceptos no se aplican a los datos nuevos y afectan negativamente a la capacidad de los modelos para generalizar.\n",
    "\n",
    "El sobreajuste es más probable con modelos no paramétricos y no lineales porque estos tipos de algoritmos de Machine Learning tienen más libertad para construir el modelo basado en el conjunto de datos , por lo tanto, pueden construir modelos poco realistas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Idealmente, deseamos seleccionar un modelo en el \"punto óptimo\" entre ajuste insuficiente y excesivo. Ésto es el objetivo, pero en la práctica se puede complicar.\n",
    "\n",
    "Existen varias maneras de evitar el sobreajuste de los modelos de Machine Learning, algunos de los cuales se mencionan a continuación.\n",
    "\n",
    "---\n",
    "\n",
    "### Validación cruzada\n",
    "\n",
    "Estándar de oro en ML, aplicado para estimar la precisión del modelo en datos no vistos. Si tienes los datos, usar un conjunto de datos de valicación también es una práctica excelente.\n",
    "\n",
    "### Detección temprana\n",
    "\n",
    "En el proceso de entrenamiento del modelo, podemos ir viendo que hasta cierto número de iteraciones el rendimiento se \"estabiliza\". Después de cierto punto, si aumenta el número de iteraciones, el modelo posiblemente tendrá una mejoría en el rendimiento en el conjunto de entrenamiento, pero el modelo se **sobrecargará** y tendrá un bajo rendimiento con el conjunto de prueba (Evitamos así un ajuste excesivo del modelo!).\n",
    "\n",
    "### Regularización\n",
    "\n",
    "Se hace para simplificar el modelo. ¿Para qué la necesitamos? Para evitar que el modelo se adapte excesivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Errores en modelos de regresión\n",
    "\n",
    "Con un modelo de regresión, predecimos o estimamos el valor numérico de una cantidad desconocida, de acuerdo con unas características dadas. \n",
    "\n",
    "La diferencia entre la predicción y el valor real es **el error**, este es una variable aleatoria, que puede depender de las características dadas.\n",
    "\n",
    "---\n",
    "\n",
    "En la actualidad hay algunas formas para estimar el rendimiento y evaluar el ajuste del modelo, algunas de ellas son: \n",
    "* Error cuadrático medio (RMSE- root mean squared error)\n",
    "* Error absoluto medio (MAE - mean absolute error) \n",
    "* R-cuadrado\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE\n",
    "Indica el ajuste absoluto del modelo a los datos, qué tan cerca están los puntos de los datos observados de los predichos en el modelo.\n",
    "\n",
    "  $$\n",
    "  RMSE  = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2},\n",
    "  $$\n",
    "  \n",
    "Como la raíz cuadrada de una varianza, RMSE se puede interpretar como la desviación estándar de la varianza inexplicada, y tiene la propiedad útil de estar en las mismas unidades que la variable de respuesta.\n",
    "\n",
    "---\n",
    "Los valores más bajos de RMSE indican un mejor ajuste. RMSE es una buena medida de la precisión con que el modelo predice la respuesta, y es el criterio más importante para ajustar si el propósito principal del modelo es la predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE\n",
    "\n",
    "$$\n",
    "  MAE  = {\\frac{1}{n} \\sum_{i=1}^n |y_i - \\hat{y}_i|},\n",
    "  $$\n",
    "\n",
    "Es el promedio de la diferencia absoluta entre el valor observado y los valores predichos. El error absoluto medio o MAE es un puntaje lineal, lo que significa que todas las diferencias individuales se ponderán por igual en el promedio.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $R^2$\n",
    "\n",
    "  $$\n",
    "  R^2 \\equiv 1 - \\frac{\\sum_i (y_i-\\hat{y})^2}{\\sum_i (y_i-\\bar{y})^2},\n",
    "  $$\n",
    "  \n",
    "R-cuadrado tiene la propiedad útil de que su escala es intuitiva, va de 0 a 1, con 0 indicando que el modelo propuesto no mejora la predicción sobre el modelo medio y 1 indica una predicción perfecta. La mejora en el modelo de regresión da como resultado aumentos proporcionales en R-cuadrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitaciones importante de RMSE y MAE\n",
    "Cada una de estas medidas es meramente un promedio o la raíz cuadrada de ese promedio de las realizaciones de los errores de prueba. \n",
    "\n",
    "El error es una variable aleatoria numérica y no se puede captar todo el comportamiento de una variable aleatoria con una sola agregación de observaciones, a menudo es una variable aleatoria muy sesgada. \n",
    "\n",
    "Cuando predecimos resultados sesgados, como precios, ingresos, ventas de artículos y muchos más, lo más probable es que el error también sea sesgado, lo que significa que en la mayoría de los casos el error es muy pequeño, pero hay relativamente pocos ejemplos que pueden tener errores extremadamente grandes. Cuando el error es muy sesgado, el promedio a menudo no dice nada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
